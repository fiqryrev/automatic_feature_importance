{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find Something Important - Feature Importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Authors**: *@mrboneclinkz*\n",
    "\n",
    "**Version**: *1.0*\n",
    "\n",
    "**Description**: This function is used to find feature importance from supervised classification machine learning models. This function applying majority vote algorithm to determine best-N features, scored by sorting the highest to the lowest feature importance scores in each model, and then stack them into best-N features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Credits**\n",
    "\n",
    "Titanic Data Set: https://www.kaggle.com/c/titanic/data\n",
    "\n",
    "Feature Engineering: https://www.kaggle.com/arthurtok/introduction-to-ensembling-stacking-in-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standard libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import time\n",
    "#Preprocessing libraries\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load in the train and test datasets\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "\n",
    "# Store our passenger ID for easy access\n",
    "PassengerId = test['PassengerId']\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mrbon\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "full_data = [train, test]\n",
    "\n",
    "# Some features of my own that I have added in\n",
    "# Gives the length of the name\n",
    "train['Name_length'] = train['Name'].apply(len)\n",
    "test['Name_length'] = test['Name'].apply(len)\n",
    "# Feature that tells whether a passenger had a cabin on the Titanic\n",
    "train['Has_Cabin'] = train[\"Cabin\"].apply(lambda x: 0 if type(x) == float else 1)\n",
    "test['Has_Cabin'] = test[\"Cabin\"].apply(lambda x: 0 if type(x) == float else 1)\n",
    "\n",
    "# Feature engineering steps taken from Sina\n",
    "# Create new feature FamilySize as a combination of SibSp and Parch\n",
    "for dataset in full_data:\n",
    "    dataset['FamilySize'] = dataset['SibSp'] + dataset['Parch'] + 1\n",
    "# Create new feature IsAlone from FamilySize\n",
    "for dataset in full_data:\n",
    "    dataset['IsAlone'] = 0\n",
    "    dataset.loc[dataset['FamilySize'] == 1, 'IsAlone'] = 1\n",
    "# Remove all NULLS in the Embarked column\n",
    "for dataset in full_data:\n",
    "    dataset['Embarked'] = dataset['Embarked'].fillna('S')\n",
    "# Remove all NULLS in the Fare column and create a new feature CategoricalFare\n",
    "for dataset in full_data:\n",
    "    dataset['Fare'] = dataset['Fare'].fillna(train['Fare'].median())\n",
    "train['CategoricalFare'] = pd.qcut(train['Fare'], 4)\n",
    "# Create a New feature CategoricalAge\n",
    "for dataset in full_data:\n",
    "    age_avg = dataset['Age'].mean()\n",
    "    age_std = dataset['Age'].std()\n",
    "    age_null_count = dataset['Age'].isnull().sum()\n",
    "    age_null_random_list = np.random.randint(age_avg - age_std, age_avg + age_std, size=age_null_count)\n",
    "    dataset['Age'][np.isnan(dataset['Age'])] = age_null_random_list\n",
    "    dataset['Age'] = dataset['Age'].astype(int)\n",
    "train['CategoricalAge'] = pd.cut(train['Age'], 5)\n",
    "# Define function to extract titles from passenger names\n",
    "def get_title(name):\n",
    "    title_search = re.search(' ([A-Za-z]+)\\.', name)\n",
    "    # If the title exists, extract and return it.\n",
    "    if title_search:\n",
    "        return title_search.group(1)\n",
    "    return \"\"\n",
    "# Create a new feature Title, containing the titles of passenger names\n",
    "for dataset in full_data:\n",
    "    dataset['Title'] = dataset['Name'].apply(get_title)\n",
    "# Group all non-common titles into one single grouping \"Rare\"\n",
    "for dataset in full_data:\n",
    "    dataset['Title'] = dataset['Title'].replace(['Lady', 'Countess','Capt', 'Col','Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n",
    "\n",
    "    dataset['Title'] = dataset['Title'].replace('Mlle', 'Miss')\n",
    "    dataset['Title'] = dataset['Title'].replace('Ms', 'Miss')\n",
    "    dataset['Title'] = dataset['Title'].replace('Mme', 'Mrs')\n",
    "\n",
    "for dataset in full_data:\n",
    "    # Mapping Sex\n",
    "    dataset['Sex'] = dataset['Sex'].map( {'female': 0, 'male': 1} ).astype(int)\n",
    "    \n",
    "    # Mapping titles\n",
    "    title_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Rare\": 5}\n",
    "    dataset['Title'] = dataset['Title'].map(title_mapping)\n",
    "    dataset['Title'] = dataset['Title'].fillna(0)\n",
    "    \n",
    "    # Mapping Embarked\n",
    "    dataset['Embarked'] = dataset['Embarked'].map( {'S': 0, 'C': 1, 'Q': 2} ).astype(int)\n",
    "    \n",
    "    # Mapping Fare\n",
    "    dataset.loc[ dataset['Fare'] <= 7.91, 'Fare'] \t\t\t\t\t\t        = 0\n",
    "    dataset.loc[(dataset['Fare'] > 7.91) & (dataset['Fare'] <= 14.454), 'Fare'] = 1\n",
    "    dataset.loc[(dataset['Fare'] > 14.454) & (dataset['Fare'] <= 31), 'Fare']   = 2\n",
    "    dataset.loc[ dataset['Fare'] > 31, 'Fare'] \t\t\t\t\t\t\t        = 3\n",
    "    dataset['Fare'] = dataset['Fare'].astype(int)\n",
    "    \n",
    "    # Mapping Age\n",
    "    dataset.loc[ dataset['Age'] <= 16, 'Age'] \t\t\t\t\t       = 0\n",
    "    dataset.loc[(dataset['Age'] > 16) & (dataset['Age'] <= 32), 'Age'] = 1\n",
    "    dataset.loc[(dataset['Age'] > 32) & (dataset['Age'] <= 48), 'Age'] = 2\n",
    "    dataset.loc[(dataset['Age'] > 48) & (dataset['Age'] <= 64), 'Age'] = 3\n",
    "    dataset.loc[ dataset['Age'] > 64, 'Age'] = 4 ;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature selection\n",
    "drop_elements = ['PassengerId', 'Name', 'Ticket', 'Cabin', 'SibSp']\n",
    "train = train.drop(drop_elements, axis = 1)\n",
    "train = train.drop(['CategoricalAge', 'CategoricalFare'], axis = 1)\n",
    "test  = test.drop(drop_elements, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Determine X and Y variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.drop([\"Survived\"],axis=1)\n",
    "y = train.Survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Pclass', 'Sex', 'Age', 'Parch', 'Fare', 'Embarked', 'Name_length',\n",
       "       'Has_Cabin', 'FamilySize', 'IsAlone', 'Title'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_name = X.columns\n",
    "col_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Split Training Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X train: 178, X test: 713, y train: 178, y test: 713 \n",
      "Length of y_train: 178, while y_test: 713\n",
      "The comparison sum of category 0 and 1 from y_train: [97 81]\n",
      "The comparison sum of category 0 and 1 from y_test: [452 261]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mrbon\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2179: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X,y,train_size=0.2,random_state=123)\n",
    "print(f\"X train: {X_train.shape[0]}, X test: {X_test.shape[0]}, y train: {y_train.shape[0]}, y test: {y_test.shape[0]} \")\n",
    "print(f\"Length of y_train: {len(y_train)}, while y_test: {len(y_test)}\")\n",
    "print(f\"The comparison sum of category 0 and 1 from y_train: {np.bincount(y_train)}\")\n",
    "print(f\"The comparison sum of category 0 and 1 from y_test: {np.bincount(y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Define Model Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Modeling libraries\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier,BaggingClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import lightgbm as lgb\n",
    "import xgboost as xg\n",
    "import catboost as cb\n",
    "from prettytable import PrettyTable\n",
    "from IPython.display import clear_output\n",
    "#Ensemble Beberapa Classifier\n",
    "clf_A = RandomForestClassifier()\n",
    "clf_B = xg.XGBClassifier()\n",
    "clf_C = lgb.LGBMClassifier(silent=True) #Ada irrelevant feature importance values, jadi di exclude\n",
    "clf_D = cb.CatBoostClassifier(verbose=False)\n",
    "clf_E = LogisticRegression()\n",
    "clf_F = SVC()\n",
    "clf_G = KNeighborsClassifier()\n",
    "clf_H = BaggingClassifier()\n",
    "clf_I = GradientBoostingClassifier()\n",
    "clf_J = AdaBoostClassifier()\n",
    "clf_total = [clf_A,clf_B,clf_C,clf_D,clf_E,clf_F,clf_G,clf_H,clf_I,clf_J]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Function Find Something Important"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FindSomethingImportant():\n",
    "    \"\"\"\n",
    "    Function to find and create an ensemble feature importance score within one or more classifier models. \n",
    "    Suggestion, you may insert the optimized hyperparameter of each model to this function.\n",
    "    \n",
    "    Particularly, in this class, you can:\n",
    "    1. Fit(X_train,y_train)\n",
    "       Train all inserted models\n",
    "    2. summarize()\n",
    "       Give the feature importance information along with the overall best feature table\n",
    "       \n",
    "    Changelog:\n",
    "    v1.0\n",
    "    - First initialization\n",
    "    - You should have prettytable, lightgbm, xgboost, and catboost installed in your notebook first\n",
    "    - This function works well to all scikitlearn classifier, lightgbm, xgboost, and catboost\n",
    "    - Not support for the automatic hyperparameter tuning\n",
    "    - Not support for all deep learning models\n",
    "    - Due to limited generalization, I used these abbrevations within my code. So, if you want to use it, please \n",
    "      set these libraries as what I named below:\n",
    "        - Numpy as np\n",
    "        - Pandas as pd\n",
    "        - Catboost as cb\n",
    "    - Require pretty table, seaborn, and matplotlib to be activated in the python environment\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self,random_state=123,limit=10,verbose=False,classifier=[RandomForestClassifier()],\\\n",
    "                show_plot = False, show_table = True):\n",
    "        \"\"\"\n",
    "        Create the class, set the parameters.\n",
    "        \n",
    "        random_state = Set your seed [Default = 123]\n",
    "        limit = Set your maximum features shown in the feature importance [Default = 10]\n",
    "        verbose = Show the track information along the process [Default = False]\n",
    "        classifier = Use only the classifier, otherwise automatically set to RandomForestClassifier. You can add\n",
    "                     some models in a list. [Default = RandomForestClassifier()]\n",
    "        show_plot = Show the plot on the summarize result [Default = False]\n",
    "        show_table = Show the importance table on the summarize result [Default = True]\n",
    "        \n",
    "        Restrictions:\n",
    "        \n",
    "        \n",
    "        \"\"\"\n",
    "\n",
    "        self.verbose = verbose\n",
    "        self.random_state = random_state\n",
    "        self.show_plot = show_plot\n",
    "        self.show_table = show_table\n",
    "        self.__train_table = False\n",
    "        self.importance = {}\n",
    "        self.__fi_score = {}\n",
    "        self.__importance_sign = {}\n",
    "        if limit > len(col_name):\n",
    "            limit = len(col_name)\n",
    "        if limit < 0 or limit >100:\n",
    "            print(\"Limit is limited between 1 - 100. Automatically set to 10\")\n",
    "            self.limit = 10\n",
    "        else:\n",
    "            self.limit = limit\n",
    "        try:\n",
    "            cache_logic = len(classifier)\n",
    "            clf_list = []\n",
    "            for i in range(len(classifier)):\n",
    "                if \"Classifier\" not in str(classifier[i].__class__):\n",
    "                    print(f\"{classifier[i]} is not classifier class, automatically remove from the list.\")\n",
    "                else:\n",
    "                    clf_list.append(classifier[i])\n",
    "            if len(clf_list) == 0:\n",
    "                print(\"Since there is no eligible classifier, automatically set to Random Forest Classifier\")\n",
    "                self.classifier = [RandomForestClassifier(random_state=self.random_state)]\n",
    "            else:\n",
    "                self.classifier = clf_list\n",
    "        except:\n",
    "            if \"Classifier\" not in str(classifier.__class__):\n",
    "                print(f\"{classifier.__class__.__name__} is not classifier class, automatically set to Random Forest Classifier\")\n",
    "                self.classifier = [RandomForestClassifier(random_state=self.random_state)]\n",
    "            else:\n",
    "                self.classifier = [classifier]\n",
    "        self.__classifier_name_list= []\n",
    "        for i in range(len(self.classifier)):\n",
    "            self.__classifier_name_list.append(self.classifier[i].__class__.__name__)\n",
    "        print(\"=================================================================\")\n",
    "        print(\"Show Importance Function v1.0\")\n",
    "        print(f\"Trying to find feature importances from {self.__classifier_name_list}\")\n",
    "        print(\"=================================================================\")\n",
    "        \n",
    "    def __importance_table_func(self,classifier_at):\n",
    "        \"\"\"\n",
    "        \n",
    "        Create the table of feature importance, sort descently\n",
    "        \n",
    "        \"\"\"\n",
    "        class_name = classifier_at.__class__.__name__\n",
    "        index = np.argsort(self.importance[class_name])\n",
    "        t = PrettyTable([\"Category name\",\"Feature Importances\",\"Score\"])\n",
    "        for i in range(self.limit):\n",
    "            t.add_row([self.__colnames[index][len(self.importance[class_name])-self.limit:][self.limit-i-1],\n",
    "                      self.importance[class_name][index][len(self.importance[class_name])-self.limit:][self.limit-i-1],\n",
    "                      self.limit-i])\n",
    "        print(t)\n",
    "        return t\n",
    "    \n",
    "    def fit(self,X,y,colnames):\n",
    "        \"\"\"\n",
    "        Train the models you've input in this class. \n",
    "        \n",
    "        X = Your X_train\n",
    "        y = Your y_train\n",
    "        colnames = The feature names in a list. Column names. If it is empty, the feature names will be set to a\n",
    "                 sequence of number from 1 to N (maximum length of your feature)\n",
    "        \n",
    "        \"\"\"\n",
    "        try:\n",
    "            cache_test = len(colnames)\n",
    "            self.__colnames = np.array(colnames)\n",
    "        except:\n",
    "            print(\"Column name is empty, automatically set to sequence number from 1 to N\")\n",
    "            self.__colnames = np.array([x+1 for x in range(np.array(X).shape[1])])\n",
    "        self.X = (X if isinstance(X,np.ndarray) else np.array(X))\n",
    "        self.y = (y if isinstance(y,np.ndarray) else np.array(y))\n",
    "        \n",
    "        if self.__train_table == False:\n",
    "            start_time_all = time.time()\n",
    "            for i in range(len(self.classifier)):\n",
    "                class_name = self.classifier[i].__class__.__name__\n",
    "                if self.verbose:\n",
    "                    print(f\"Training Process on {class_name}\")\n",
    "                start_time = time.time()\n",
    "                self.classifier[i].fit(self.X,self.y)\n",
    "                elapsed_time = time.time() - start_time\n",
    "                if self.verbose:\n",
    "                    print(\"=================================================================\")\n",
    "                    print(f\"Training Complete\")\n",
    "                    print(f\"Elapsed: {time.strftime('%H:%M:%S', time.gmtime(elapsed_time))}\")\n",
    "                    print(\"=================================================================\")\n",
    "                try:  \n",
    "                    try:\n",
    "                        self.importance[class_name] = self.classifier[i].feature_importances_\n",
    "                    except:\n",
    "                        self.importance[class_name] = np.array(self.classifier[i].get_feature_importance(\\\n",
    "                                                                                 cb.Pool(self.X,label=self.y)))\n",
    "                    calc_index = np.argsort(self.importance[class_name])\n",
    "                    calc_fi_score = 0\n",
    "                    col_name_loop = []\n",
    "                    for j in range(self.limit):\n",
    "                        calc_fi_score += self.importance[class_name][calc_index][len(self.importance[class_name]\\\n",
    "                                                                                 )-self.limit:][self.limit-j-1]\n",
    "                        col_name_loop.append(self.__colnames[calc_index][len(self.importance[class_name])-self.limit:][\\\n",
    "                                      self.limit-j-1])\n",
    "                    self.__importance_sign[class_name] = col_name_loop\n",
    "                    self.__fi_score[class_name] = calc_fi_score\n",
    "                except AttributeError:\n",
    "                    print(f\"{class_name} has no attribute Feature Importance. Stored nothing.\")\n",
    "                    self.importance[class_name] = np.array([0 for x in range(len(col_name))])\n",
    "                    self.__importance_sign[class_name] = col_name\n",
    "                    self.__fi_score[class_name] = 0\n",
    "                \n",
    "            clear_output()\n",
    "            elapsed_time_all = time.time() - start_time_all\n",
    "            print(\"=================================================================\")\n",
    "            print(f\"Training All Classifiers Completed\")\n",
    "            print(f\"Elapsed: {time.strftime('%H:%M:%S', time.gmtime(elapsed_time_all))}\")\n",
    "            print(\"=================================================================\")\n",
    "            self.__train_table = True\n",
    "        else:\n",
    "            print(\"Data have already been trained. Try summarize()\")\n",
    "\n",
    "    def summarize(self):\n",
    "        \"\"\"\n",
    "        \n",
    "        Summarize the feature importance by table and or bar chart. Also, return a data frame, as a\n",
    "        result from majority voting of feature importance from all classifiers.\n",
    "        \n",
    "        \"\"\"\n",
    "        all_class = []\n",
    "        for i in range(len(self.classifier)):\n",
    "            class_name = self.classifier[i].__class__.__name__\n",
    "            calc_index = np.argsort(self.importance[class_name])\n",
    "            all_class.append(self.__importance_sign[class_name])\n",
    "            if self.show_table:\n",
    "                print(f\"Top {self.limit} of {class_name} Feature Importances:\")\n",
    "                self.__importance_table_func(self.classifier[i])          \n",
    "            print(f\"FI Cummulative Score of {class_name}: {self.__fi_score[class_name]}\")\n",
    "            print(\"\")\n",
    "        top_features = {}\n",
    "        for i in all_class:\n",
    "            for index,value in enumerate(i):\n",
    "                score = (len(i)-index)\n",
    "                if value not in top_features:\n",
    "                    top_features[value] = 1*score\n",
    "                else:\n",
    "                    top_features[value] += score\n",
    "        total_feature_include = self.limit*len(self.classifier)\n",
    "        best_features = sorted(top_features.items(), key=lambda x: x[1],reverse=True)\n",
    "        self.most_important_features = pd.DataFrame(best_features[:self.limit])\n",
    "        self.most_important_features.columns = [\"Feature\",\"Score\"]\n",
    "        self.most_important_features[\"Percentage\"] = self.most_important_features[\"Score\"].map(lambda x: 100*round(x/total_feature_include,2))\n",
    "        if self.show_plot:\n",
    "            self.most_important_features.set_index(\"Feature\")[\"Percentage\"].plot(kind=\"bar\",figsize=(14,7),\\\n",
    "            title=\"Top Feature Overall\")\n",
    "        return self.most_important_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Implement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================================================\n",
      "Training All Classifiers Completed\n",
      "Elapsed: 00:00:32\n",
      "=================================================================\n",
      "Wall time: 32.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "find_importance_all = FindSomethingImportant(random_state=123,limit=11,verbose=True,\\\n",
    "                             classifier=clf_total,\\\n",
    "                             show_plot = True, show_table = False)\n",
    "find_importance_all.fit(X_train,y_train,col_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FI Cummulative Score of RandomForestClassifier: 1.0\n",
      "\n",
      "FI Cummulative Score of XGBClassifier: 0.9999999906867743\n",
      "\n",
      "FI Cummulative Score of LGBMClassifier: 570\n",
      "\n",
      "FI Cummulative Score of CatBoostClassifier: 100.0\n",
      "\n",
      "FI Cummulative Score of KNeighborsClassifier: 0\n",
      "\n",
      "FI Cummulative Score of BaggingClassifier: 0\n",
      "\n",
      "FI Cummulative Score of GradientBoostingClassifier: 1.0\n",
      "\n",
      "FI Cummulative Score of AdaBoostClassifier: 1.0\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Score</th>\n",
       "      <th>Percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Name_length</td>\n",
       "      <td>71</td>\n",
       "      <td>81.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pclass</td>\n",
       "      <td>64</td>\n",
       "      <td>73.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Age</td>\n",
       "      <td>60</td>\n",
       "      <td>68.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Title</td>\n",
       "      <td>59</td>\n",
       "      <td>67.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fare</td>\n",
       "      <td>56</td>\n",
       "      <td>64.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>FamilySize</td>\n",
       "      <td>51</td>\n",
       "      <td>58.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Sex</td>\n",
       "      <td>46</td>\n",
       "      <td>52.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Has_Cabin</td>\n",
       "      <td>39</td>\n",
       "      <td>44.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Embarked</td>\n",
       "      <td>36</td>\n",
       "      <td>41.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Parch</td>\n",
       "      <td>32</td>\n",
       "      <td>36.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>IsAlone</td>\n",
       "      <td>14</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Feature  Score  Percentage\n",
       "0   Name_length     71        81.0\n",
       "1        Pclass     64        73.0\n",
       "2           Age     60        68.0\n",
       "3         Title     59        67.0\n",
       "4          Fare     56        64.0\n",
       "5    FamilySize     51        58.0\n",
       "6           Sex     46        52.0\n",
       "7     Has_Cabin     39        44.0\n",
       "8      Embarked     36        41.0\n",
       "9         Parch     32        36.0\n",
       "10      IsAlone     14        16.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "find_importance_all.summarize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
